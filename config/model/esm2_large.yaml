# @package model
_target_: transformers.AutoModelForCausalLM

# Model configuration
model_name: "facebook/esm2_t36_3B_UR50D"
pretrained: true
freeze_embeddings: false

# Model parameters
max_length: 1024
vocab_size: 33  # ESM2 vocabulary size
hidden_size: 2560
num_attention_heads: 40
num_hidden_layers: 36
intermediate_size: 10240
